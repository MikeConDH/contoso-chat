{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeConDH/contoso-chat/blob/main/Custom_RAG_Pipeline_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Extensions to RAG Application\n",
        "\n",
        "In the following notebook, we'll leverage [Cohere's](https://txt.cohere.com/) [impressive](https://txt.cohere.com/introducing-embed-v3/) [work](https://txt.cohere.com/using-llms-for-search/) to augment our simple RAG application by adding:\n",
        "\n",
        "- their v3 embeddings model\n",
        "- a reranking system\n",
        "\n",
        "We'll also extend our simple examples to work over the entire blog corpus of [Coding Temple](https://www.codingtemple.com/blog/coding-in-public-help-battle-imposter-syndrome-and-inspire-others/)."
      ],
      "metadata": {
        "id": "WOG8oIgptCjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "\n",
        "We'll grab some dependencies for our RAG application, then our web scraping system!"
      ],
      "metadata": {
        "id": "KCAKMkcctsE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hlq2p8O0Bl7U",
        "outputId": "9388c646-b067-4dcc-c68a-62804ecb8058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai cohere tiktoken -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll need to provide an OpenAI as well as a Cohere API!\n",
        "\n",
        "The Cohere trial API key will be more than enough for this notebook!"
      ],
      "metadata": {
        "id": "EYg276-Mu_IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Open AI API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_6xT5u8K5-r",
        "outputId": "b8b54506-9fc5-406b-f569-22f114d99038"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open AI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlAXTs7pLPOo",
        "outputId": "267238bc-42f9-4279-e060-54bf879d9604"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cohere API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio selenium unstructured -qU"
      ],
      "metadata": {
        "id": "6q3AKCDEBtQo",
        "outputId": "eccbcd0f-503b-4dc5-891c-f22709cb091b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boilerplate\n",
        "\n",
        "We need to use `nest_asyncio` to avoid any issues with Jupyter and async methods."
      ],
      "metadata": {
        "id": "WxIzm4-3tw42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "wZfobKGCFoUB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping\n",
        "\n",
        "Here we will scrape the Coding Temple blogs to get all their current blogs!"
      ],
      "metadata": {
        "id": "0mIcXQKgt5bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader, SeleniumURLLoader\n",
        "\n",
        "loaders = SeleniumURLLoader(urls=[\"https://www.codingtemple.com/post-sitemap.xml\"])\n",
        "data = loaders.load()"
      ],
      "metadata": {
        "id": "V6gI1YT-G4nA",
        "outputId": "84a57b89-efe6-4203-bf54-3e709362d372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "documents = []\n",
        "\n",
        "urls = [url for url in re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', data[0].page_content)]"
      ],
      "metadata": {
        "id": "TFXBcldzHDM9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = SeleniumURLLoader(urls=urls[1:])\n",
        "documents = loaders.load()"
      ],
      "metadata": {
        "id": "SN-3szi3HkZo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")"
      ],
      "metadata": {
        "id": "NmXFS4jmJykv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_documents = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "tjLKKq89KP75"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Pipeline\n",
        "\n",
        "Now that we have our documents, and we've split them - let's create our `VectorStore`!"
      ],
      "metadata": {
        "id": "grXzFzSLvIIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu -qU"
      ],
      "metadata": {
        "id": "f5CLmoHcKd_R",
        "outputId": "98c28cbe-cebf-4e5c-98ec-af20197a0e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cohere Embeddings\n",
        "\n",
        "We'll use Cohere's embeddings which are shown to be the most performant on the [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)!"
      ],
      "metadata": {
        "id": "emQU9mcHveZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import CohereEmbeddings\n",
        "\n",
        "embeddings = CohereEmbeddings(cohere_api_key=os.environ.get(\"COHERE_API_KEY\"))"
      ],
      "metadata": {
        "id": "xnTOlwHxLkp_",
        "outputId": "b044ad50-d838-4640-d6e0-2b499f7eee3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.cohere.CohereEmbeddings` was deprecated in langchain-community 0.0.30 and will be removed in 0.2.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import CohereEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(\n",
        "    split_documents, embedding=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "h2Q5nR67Lw8w"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reranking Pipeline\n",
        "\n",
        "We're going to fetch a lot of initial documents for reranking.\n",
        "\n",
        "The basic idea is to cast a wide net - and then rerank the subset by relevance and only keep the `top_k` documents (default of 3) to use as context to augment the prompt."
      ],
      "metadata": {
        "id": "IaRGE9fFvOXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})"
      ],
      "metadata": {
        "id": "fnqIld1CMAa1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(user_agent=\"coding_temple_demo\", cohere_api_key=os.environ.get(\"COHERE_API_KEY\"))\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=base_retriever\n",
        ")"
      ],
      "metadata": {
        "id": "5_-6puVwOyrN",
        "outputId": "ca18a982-085a-4686-8e0b-12c8ae3f4fb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.retrievers.document_compressors.cohere_rerank.CohereRerank` was deprecated in langchain 0.0.30 and will be removed in 0.2.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import CohereRerank`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Up RAG\n",
        "\n",
        "Now we can build some helper functions to create our simple RAG chain!\n",
        "\n",
        "We'll be using the [LCEL](https://python.langchain.com/docs/expression_language/) to achieve this goal."
      ],
      "metadata": {
        "id": "W1IfwYu_vdUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
      ],
      "metadata": {
        "id": "NMuKgK4fMFLs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "rhMpzJhIMMch"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
        "    buffer = \"\"\n",
        "    for dialogue_turn in chat_history:\n",
        "        human = \"Human: \" + dialogue_turn[0]\n",
        "        ai = \"Assistant: \" + dialogue_turn[1]\n",
        "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
        "    return buffer"
      ],
      "metadata": {
        "id": "LlGQThwiMSI2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
        ")"
      ],
      "metadata": {
        "id": "7zp4tc7rMedA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import format_document\n",
        "\n",
        "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
        "\n",
        "def _combine_documents(\n",
        "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
        "):\n",
        "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
        "    return document_separator.join(doc_strings)"
      ],
      "metadata": {
        "id": "is_h6G9_MsAJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "loaded_memory = RunnablePassthrough.assign(\n",
        "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
        ")\n",
        "\n",
        "\n",
        "standalone_question = {\n",
        "    \"standalone_question\": {\n",
        "        \"question\": lambda x: x[\"question\"],\n",
        "        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n",
        "    }\n",
        "    | CONDENSE_QUESTION_PROMPT\n",
        "    | ChatOpenAI(temperature=0)\n",
        "    | StrOutputParser(),\n",
        "}\n",
        "\n",
        "\n",
        "retrieved_documents = {\n",
        "    \"docs\": itemgetter(\"standalone_question\") | compression_retriever,\n",
        "    \"question\": lambda x: x[\"standalone_question\"],\n",
        "}\n",
        "\n",
        "\n",
        "final_inputs = {\n",
        "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
        "    \"question\": itemgetter(\"question\"),\n",
        "}\n",
        "\n",
        "\n",
        "answer = {\n",
        "    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(),\n",
        "    \"docs\": itemgetter(\"docs\"),\n",
        "}\n",
        "\n",
        "\n",
        "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
      ],
      "metadata": {
        "id": "I0FCQ24FMUox",
        "outputId": "355b0aa0-4cc6-4067-f41b-380ba015253a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"question\" : \"What are some ways to avoid imposter syndrome?\"}"
      ],
      "metadata": {
        "id": "U7xUEB6_M4iy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = final_chain.invoke(inputs)"
      ],
      "metadata": {
        "id": "Qn7PEhq2M9gL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGJPHAJNNcsB",
        "outputId": "3b632ef4-8915-445f-abe2-5265c284bd34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': AIMessage(content='Some strategies to overcome imposter syndrome include acknowledging your achievements, seeking support from communities like DEV Community and Stack Overflow, embracing continuous learning, and showcasing your programming skills publicly.', response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 369, 'total_tokens': 403}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-05841ed7-e866-4594-816e-2b4c5607561a-0'),\n",
              " 'docs': [Document(page_content='Overcoming Imposter Syndrome\\n\\nEncourage someone experiencing imposter syndrome by validating their feelings while emphasizing their achievements. Offer constructive feedback and remind them of past successes. Encourage them to join programming communities like DEV Community for support, networking opportunities, and skill development.\\n\\nThe secret to overcoming imposter syndrome lies in self-awareness, acceptance of imperfections, embracing continuous learning, seeking mentorship or peer support through platforms like Stack Overflow, and celebrating personal milestones regardless of how small they may seem at first glance.\\n\\nConclusion', metadata={'source': 'https://www.codingtemple.com/blog/coding-in-public-help-battle-imposter-syndrome-and-inspire-others/', 'title': 'Coding In Public: Help Battle Imposter Syndrome and Inspire Others | Coding Temple', 'description': 'Discover how \"Coding In Public: Help Battle Imposter Syndrome and Inspire Others\" can transform your tech career, boost confidence, and motivate fellow coders.', 'language': 'en-US', 'relevance_score': 0.99780875}),\n",
              "  Document(page_content='In this blog post, we will discuss practical strategies for overcoming impostor syndrome as you venture into the world of software engineering and technology. We’ll explore methods for showcasing your programming skills through various platforms, allowing you to build confidence in your abilities while demonstrating them to potential employers or collaborators.\\n\\nOvercoming Impostor Syndrome in Tech\\n\\nImpostor syndrome is a common issue faced by many individuals entering the tech industry, especially those transitioning from other careers. To overcome this feeling of inadequacy and self-doubt, it’s essential to recognize its signs and implement strategies to manage it effectively.', metadata={'source': 'https://www.codingtemple.com/blog/coding-in-public-help-battle-imposter-syndrome-and-inspire-others/', 'title': 'Coding In Public: Help Battle Imposter Syndrome and Inspire Others | Coding Temple', 'description': 'Discover how \"Coding In Public: Help Battle Imposter Syndrome and Inspire Others\" can transform your tech career, boost confidence, and motivate fellow coders.', 'language': 'en-US', 'relevance_score': 0.99522626}),\n",
              "  Document(page_content='Overcoming imposter syndrome in tech requires you to recognize your skills and abilities, as well as take steps to improve them. With this newfound confidence, it’s time to start showcasing your programming skills.\\n\\n“Overcome Impostor Syndrome in tech by acknowledging your achievements, seeking support, and embracing continuous learning. #CodingInPublic #CareerDevelopmentTips”\\n\\nClick to Tweet\\n\\nShowcasing Your Programming Skills\\n\\nIt’s essential to showcase your programming skills publicly. This not only helps build confidence but also demonstrates your expertise to potential employers and collaborators. Here are some ideas for displaying your skills:', metadata={'source': 'https://www.codingtemple.com/blog/coding-in-public-help-battle-imposter-syndrome-and-inspire-others/', 'title': 'Coding In Public: Help Battle Imposter Syndrome and Inspire Others | Coding Temple', 'description': 'Discover how \"Coding In Public: Help Battle Imposter Syndrome and Inspire Others\" can transform your tech career, boost confidence, and motivate fellow coders.', 'language': 'en-US', 'relevance_score': 0.9892233})]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"question\" : \"What does an AI business leader need to know about building internal training programs?\"}"
      ],
      "metadata": {
        "id": "IPYT7iKNwFIL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = final_chain.invoke(inputs)"
      ],
      "metadata": {
        "id": "o3dGgBcxwGYY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPC621N3xaSf",
        "outputId": "7238100d-92ee-4161-ccfe-8f4200677702"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': AIMessage(content='An AI business leader needs to know that building internal training programs is essential for ensuring long-term success and competitiveness in the age of AI. They should prioritize investing in reskilling their workforce and embracing the opportunities and challenges that generative AI brings. Additionally, utilizing generative AI to create personalized training programs tailored to the specific needs and skill sets of each worker can help improve performance and job satisfaction. It is important to assess current employee skills, predict future skill requirements, and design and manage programs to bridge the skills gap effectively.', response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 439, 'total_tokens': 544}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-904b1203-f00c-4fe2-9b05-f033a1dc1ab0-0'),\n",
              " 'docs': [Document(page_content='Some insightful resources:\\n\\nHarvard Business Review: The New World of Work: Keith Ferrazzi, author of “Competing in the New World of Work”: \\xa0 Youtube\\n\\nHarvard Business Review: The New World of Work: Ryan Roslansky, LinkedIn CEO\\xa0 Youtube\\n\\nIn many industries, companies that do not effectively leverage AI will be unable to compete with those that do. Business leaders must prioritize accordingly, investing in reskilling their workforce and embracing the opportunities and challenges that generative AI brings. By proactively addressing skills gaps, collaborating with technology, and adapting to the rapidly evolving landscape, organizations can ensure their long-term success and competitiveness in the age of AI.\\n\\nCoding Temple\\n\\nShare', metadata={'source': 'https://www.codingtemple.com/blog/generative-ai-embracing-opportunities-and-navigating-challenges-in-the-workplace/', 'title': 'Generative AI: Embracing Opportunities and Navigating Challenges in the Workplace | Coding Temple', 'description': 'Discover the positive and negative implications of generative AI in the workplace and how companies can navigate this new reality.', 'language': 'en-US', 'relevance_score': 0.39099893}),\n",
              "  Document(page_content='Managing the L&D Function\\n\\nFor companies without extensive Learning and Development (L&D) leadership, figuring out how to effectively create the time and mindshare to design a strategy can seem daunting. Fully-managed L & D solutions can help by assessing skills gaps, designing programs, and driving participation, ensuring that companies are prepared to compete in the changing landscape.\\n\\nAddressing Negative Implications\\n\\nGenerative AI will automate many tasks, which could lead to the displacement of millions of jobs, while also creating new opportunities in fields like data analysis, AI training, and maintenance. The outcome for companies and their employees depends on how they approach this paradox.', metadata={'source': 'https://www.codingtemple.com/blog/generative-ai-embracing-opportunities-and-navigating-challenges-in-the-workplace/', 'title': 'Generative AI: Embracing Opportunities and Navigating Challenges in the Workplace | Coding Temple', 'description': 'Discover the positive and negative implications of generative AI in the workplace and how companies can navigate this new reality.', 'language': 'en-US', 'relevance_score': 0.39035964}),\n",
              "  Document(page_content='Personalized Training and Skill Development\\n\\nGenerative AI can also be utilized to create personalized training programs tailored to the specific needs and skill sets of each worker or role. This can help to improve performance and job satisfaction. As the World Economic Forum predicts, advancements in technology will displace 85 million jobs by 2025 but also create 97 million new jobs in areas such as data analysis, software development, and cybersecurity. This presents a significant opportunity for companies to reskill their workforce proactively, provided they take the necessary steps:\\n\\n1. Assessing current employee skills\\n\\n2. Predicting future skill requirements\\n\\n3. Designing and managing programs to bridge the skills gap', metadata={'source': 'https://www.codingtemple.com/blog/generative-ai-embracing-opportunities-and-navigating-challenges-in-the-workplace/', 'title': 'Generative AI: Embracing Opportunities and Navigating Challenges in the Workplace | Coding Temple', 'description': 'Discover the positive and negative implications of generative AI in the workplace and how companies can navigate this new reality.', 'language': 'en-US', 'relevance_score': 0.36715683})]}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(inputs, {\"answer\": result[\"answer\"].content})"
      ],
      "metadata": {
        "id": "kUhhlKXPwHNd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6qkdha2wHzu",
        "outputId": "97ac31e1-5b30-4bff-bea8-79a7495344d4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='What does an AI business leader need to know about building internal training programs?'),\n",
              "  AIMessage(content='An AI business leader needs to know that building internal training programs is essential for ensuring long-term success and competitiveness in the age of AI. They should prioritize investing in reskilling their workforce and embracing the opportunities and challenges that generative AI brings. Additionally, utilizing generative AI to create personalized training programs tailored to the specific needs and skill sets of each worker can help improve performance and job satisfaction. It is important to assess current employee skills, predict future skill requirements, and design and manage programs to bridge the skills gap effectively.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}